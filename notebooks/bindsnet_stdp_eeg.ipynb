{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "try:\n",
    "    from bindsnet.network import Network\n",
    "except:\n",
    "    from bindsnet.network import Network\n",
    "\n",
    "from bindsnet.learning import PostPre\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.network.nodes import LIFNodes, Input\n",
    "from bindsnet.analysis.plotting import plot_spikes\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class Topographies2SNN(Network):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape: Tuple,\n",
    "                 fc_layers: List[int],\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        fc1_layer = self._add_layer(fc_layers[0], name='fc1_layer')\n",
    "        for band_name in ['Delta','Theta','Alpha','Beta','Gamma']:\n",
    "            layer_name = f'{band_name}-topography'\n",
    "            input_layer = self._add_input_layer(name=layer_name, shape=input_shape)\n",
    "            self._add_connection(input_layer, fc1_layer,\n",
    "                                 layer_name, 'fc1_layer')\n",
    "\n",
    "        prev_layer = fc1_layer\n",
    "        for i, n in enumerate(fc_layers[1:]):\n",
    "            layer = self._add_layer(n, name=f'fc{i+2}_layer')\n",
    "            self._add_connection(prev_layer, layer,\n",
    "                                 f'fc{i+1}_layer', f'fc{i+2}_layer')\n",
    "            prev_layer = layer\n",
    "\n",
    "    def _add_input_layer(self, name, shape):\n",
    "        input_layer = Input(\n",
    "            n=math.prod(shape),\n",
    "            shape=shape,\n",
    "            traces=True,\n",
    "            tc_trace=20.0\n",
    "        )\n",
    "        self.add_layer(input_layer, name=name)\n",
    "        return input_layer\n",
    "\n",
    "    def _add_layer(self, n, name):\n",
    "        layer = LIFNodes(\n",
    "            n=n,\n",
    "            traces=True,\n",
    "            rest=0.0,\n",
    "            thresh=10,\n",
    "        )\n",
    "        self.add_layer(layer, name=name)\n",
    "        return layer\n",
    "\n",
    "    def _add_connection(self, source, target,\n",
    "                        source_name, target_name\n",
    "    ):\n",
    "        w = 0.5 * torch.rand(source.n, target.n)\n",
    "        conn = Connection(\n",
    "            source=source,\n",
    "            target=target,\n",
    "            w=w,\n",
    "            update_rule=PostPre,\n",
    "            # norm=78.4,\n",
    "            # nu=(1e-4, 1e-2),\n",
    "        )\n",
    "        self.add_connection(conn,\n",
    "                            source=source_name,\n",
    "                            target=target_name)\n",
    "\n",
    "\n",
    "bands = {\n",
    "    'Delta': (.5, 4),\n",
    "    # 'Theta': (4, 8),\n",
    "    # 'Alpha': (8, 14),\n",
    "    # 'Beta': (14, 32),\n",
    "    # 'Gamma': (32, 62),\n",
    "}\n",
    "\n",
    "def merge_n_shuffle_tensors(*dicts: Dict, label_tensor):\n",
    "    merged_dict = {}\n",
    "\n",
    "    batch_size = list(dicts[0].values())[0].shape[1]\n",
    "    # Generate random permutations for shuffling along axis 1\n",
    "    perm_indices = torch.randperm(3 * batch_size)\n",
    "    label_tensor = label_tensor[perm_indices]\n",
    "\n",
    "    # Loop through the keys in one of the dictionaries (assuming they all have the same keys)\n",
    "    for key in dicts[0].keys():\n",
    "        # Concatenate the tensors along the second dimension (b)\n",
    "        merged_value = torch.cat([d[key] for d in dicts], dim=1)\n",
    "\n",
    "        # Assign the merged tensor to the corresponding key in the merged dictionary\n",
    "        merged_dict[key] = merged_value[:, perm_indices, :, :]\n",
    "    return merged_dict, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Our Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "output_neurons = 64\n",
    "\n",
    "fc_layers = [121, output_neurons]\n",
    "snn = Topographies2SNN(input_shape=(11, 11),\n",
    "                       fc_layers=fc_layers,\n",
    "                       )\n",
    "ouput_layer_name = f'fc{len(fc_layers)}_layer'\n",
    "output_path_dir = Path('../datasets/EEG_data_for_Mental_Attention_State_Detection/preprocessed_resonators')\n",
    "\n",
    "trial = '3'\n",
    "band_name = 'Delta'\n",
    "minute = 3\n",
    "step = 0\n",
    "# prefer to have batch size that is divided by 3 and its divide the number 645\n",
    "# batch_size = 129\n",
    "batch_size = 30\n",
    "update_step = 1\n",
    "update_interval = batch_size * update_step\n",
    "sim_time = 5000\n",
    "# sim_time = 153600 // 4\n",
    "labeled_inputs = {\n",
    "    key: {\n",
    "        f'{band_name}-topography': torch.load(output_path_dir / trial / band_name / f'{minute + 10*i}.pt')[:sim_time,\n",
    "                                   step*batch_size//3:(step+1)*batch_size//3, :, :]\n",
    "        for band_name in bands.keys()\n",
    "    }\n",
    "    for i, key in enumerate(['focus', 'unfocus', 'drowsed'])\n",
    "}\n",
    "origin_label_tensor = torch.tensor([0] * (batch_size//3) +\n",
    "                                   [1] * (batch_size//3) +\n",
    "                                   [2] * (batch_size//3))\n",
    "\n",
    "spike_record = torch.zeros((update_interval, sim_time, output_neurons))\n",
    "n_classes = 3\n",
    "assignments = -torch.ones(output_neurons)\n",
    "proportions = torch.zeros((output_neurons, n_classes))\n",
    "rates = torch.zeros((output_neurons, n_classes))\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "labels = []\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "spikes = {}\n",
    "for layer in set(snn.layers):\n",
    "    if layer.endswith('topography'):\n",
    "        continue\n",
    "    spikes[layer] = Monitor(\n",
    "        snn.layers[layer], state_vars=[\"s\"], time=sim_time,\n",
    "    )\n",
    "    snn.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 33.33 (last), 33.33 (average), 33.33 (best)\n",
      "Proportion weighting accuracy: 33.33 (last), 33.33 (average), 33.33 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 40.00 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 41.67 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 42.22 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 44.44 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 43.33 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 45.83 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 44.00 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 46.67 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 44.44 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 47.22 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 44.76 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 47.62 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 45.00 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 47.92 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 45.19 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 48.15 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n",
      "\n",
      "All activity accuracy: 46.67 (last), 45.33 (average), 46.67 (best)\n",
      "Proportion weighting accuracy: 50.00 (last), 48.33 (average), 50.00 (best)\n",
      "\n",
      "{'fc2_layer': tensor(11153), 'fc1_layer': tensor(31069)}\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for step in range(0, update_step*10 + 1):\n",
    "    if step % update_step == 0 and step > 0:\n",
    "        label_tensor = torch.tensor(labels)\n",
    "\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(\n",
    "            spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "        )\n",
    "        proportion_pred = proportion_weighting(\n",
    "            spikes=spike_record,\n",
    "            assignments=assignments,\n",
    "            proportions=proportions,\n",
    "            n_labels=n_classes,\n",
    "        )\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(\n",
    "            100\n",
    "            * torch.sum(label_tensor.long() == all_activity_pred).item()\n",
    "            / len(label_tensor)\n",
    "        )\n",
    "        accuracy[\"proportion\"].append(\n",
    "            100\n",
    "            * torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "            / len(label_tensor)\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "            % (\n",
    "                accuracy[\"all\"][-1],\n",
    "                np.mean(accuracy[\"all\"]),\n",
    "                np.max(accuracy[\"all\"]),\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f\"\n",
    "            \" (best)\\n\"\n",
    "            % (\n",
    "                accuracy[\"proportion\"][-1],\n",
    "                np.mean(accuracy[\"proportion\"]),\n",
    "                np.max(accuracy[\"proportion\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(\n",
    "            spikes=spike_record,\n",
    "            labels=label_tensor,\n",
    "            n_labels=n_classes,\n",
    "            rates=rates,\n",
    "        )\n",
    "\n",
    "        labels = []\n",
    "\n",
    "    inputs, label_tensor = merge_n_shuffle_tensors(labeled_inputs['focus'], labeled_inputs['unfocus'], labeled_inputs['drowsed'],\n",
    "                                                   label_tensor=origin_label_tensor)\n",
    "    labels.extend(label_tensor.tolist())\n",
    "\n",
    "    # Run the network on the input.\n",
    "    snn.run(inputs=inputs, time=sim_time)\n",
    "    s = spikes[ouput_layer_name].get(\"s\").permute((1, 0, 2))\n",
    "    spike_record[\n",
    "                (step * batch_size) % update_interval :\n",
    "                (step * batch_size % update_interval) + s.size(0)\n",
    "            ] = s\n",
    "    spikes_output = {\n",
    "        monitor_name: monitor.get('s')\n",
    "        for monitor_name, monitor in spikes.items()\n",
    "    }\n",
    "    print({monitor_name: monitor.get('s').sum() for monitor_name, monitor in spikes.items()})\n",
    "    # plot_spikes(spikes_output)\n",
    "    # plt.show()\n",
    "    snn.reset_state_variables()  # Reset state variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Using Diel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "output_path_dir = Path('../datasets/EEG_data_for_Mental_Attention_State_Detection/preprocessed_resonators')\n",
    "\n",
    "trial = '3'\n",
    "band_name = 'Delta'\n",
    "minute = 3\n",
    "step = 0\n",
    "# prefer to have batch size that is divided by 3 and its divide the number 645\n",
    "# batch_size = 129\n",
    "batch_size = 15\n",
    "update_step = 1\n",
    "update_interval = batch_size * update_step\n",
    "sim_time = 2500\n",
    "# sim_time = 153600 // 4\n",
    "labeled_inputs = {\n",
    "    key: {\n",
    "        f'{band_name}-topography': torch.load(output_path_dir / trial / band_name / f'{minute + 10*i}.pt')[:sim_time,\n",
    "                                   step*batch_size//3:(step+1)*batch_size//3, :, :]\n",
    "        for band_name in bands.keys()\n",
    "    }\n",
    "    for i, key in enumerate(['focus',\n",
    "                             'unfocus',\n",
    "                             'drowsed'\n",
    "                             ])\n",
    "}\n",
    "origin_label_tensor = torch.tensor([0] * (batch_size//3) +\n",
    "                                   [1] * (batch_size//3) +\n",
    "                                   [2] * (batch_size//3)\n",
    "                                   )\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_assignments,\n",
    "    plot_input,\n",
    "    plot_performance,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    "    plot_weights,\n",
    ")\n",
    "\n",
    "n_neurons = 100\n",
    "snn = DiehlAndCook2015(\n",
    "    n_inpt= 11 * 11,\n",
    "    # n_inpt=5 * 11 * 11,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=22.5,\n",
    "    inh=22.5,\n",
    "    dt=1,\n",
    "    # norm=78.4,\n",
    "    norm=78.4,\n",
    "    nu=(1e-5, 1e-1),\n",
    "    theta_plus=0.05,\n",
    "    inpt_shape=(1, 11, 11),\n",
    "    # inpt_shape=(5, 11, 11),\n",
    ")\n",
    "# Set up monitors for spikes and voltages\n",
    "spikes = {}\n",
    "for layer in set(snn.layers):\n",
    "    spikes[layer] = Monitor(\n",
    "        snn.layers[layer], state_vars=[\"s\"], time=sim_time\n",
    "    )\n",
    "    snn.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "output_layer_name = \"Ae\"\n",
    "spike_record = torch.zeros((update_interval, sim_time, n_neurons))\n",
    "assignments = -torch.ones(n_neurons)\n",
    "proportions = torch.zeros((n_neurons, n_classes))\n",
    "rates = torch.zeros((n_neurons, n_classes))\n",
    "\n",
    "inpt_ims, inpt_axes = None, None\n",
    "spike_ims, spike_axes = None, None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes, voltage_ims = None, None\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(\n",
    "    snn.layers[\"Ae\"], [\"v\"], time=sim_time,\n",
    ")\n",
    "inh_voltage_monitor = Monitor(\n",
    "    snn.layers[\"Ai\"], [\"v\"], time=sim_time,\n",
    ")\n",
    "snn.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "snn.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "115.2"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*.9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1001 [00:19<?, ?it/s]\u001B[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 57\u001B[0m\n\u001B[0;32m     54\u001B[0m labels\u001B[38;5;241m.\u001B[39mextend(label_tensor\u001B[38;5;241m.\u001B[39mtolist())\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# Run the network on the input.\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m \u001B[43msnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msim_time\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m s \u001B[38;5;241m=\u001B[39m spikes[output_layer_name]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     59\u001B[0m spike_record[\n\u001B[0;32m     60\u001B[0m             (step \u001B[38;5;241m*\u001B[39m batch_size) \u001B[38;5;241m%\u001B[39m update_interval :\n\u001B[0;32m     61\u001B[0m             (step \u001B[38;5;241m*\u001B[39m batch_size \u001B[38;5;241m%\u001B[39m update_interval) \u001B[38;5;241m+\u001B[39m s\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     62\u001B[0m         ] \u001B[38;5;241m=\u001B[39m s\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\bindsnet\\network\\network.py:450\u001B[0m, in \u001B[0;36mNetwork.run\u001B[1;34m(self, inputs, time, one_step, **kwargs)\u001B[0m\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;66;03m# # Get input to all layers.\u001B[39;00m\n\u001B[0;32m    446\u001B[0m     \u001B[38;5;66;03m# current_inputs.update(self._get_inputs())\u001B[39;00m\n\u001B[0;32m    447\u001B[0m \n\u001B[0;32m    448\u001B[0m     \u001B[38;5;66;03m# Record state variables of interest.\u001B[39;00m\n\u001B[0;32m    449\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmonitors:\n\u001B[1;32m--> 450\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmonitors\u001B[49m\u001B[43m[\u001B[49m\u001B[43mm\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecord\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;66;03m# Re-normalize connections.\u001B[39;00m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnections:\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\bindsnet\\network\\monitors.py:82\u001B[0m, in \u001B[0;36mMonitor.record\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;124;03mAppends the current value of the recorded state variables to the recording.\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_vars:\n\u001B[1;32m---> 82\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;66;03m# self.recording[v].append(data.detach().clone().to(self.device))\u001B[39;00m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecording[v]\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m     85\u001B[0m         torch\u001B[38;5;241m.\u001B[39mempty_like(data, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mcopy_(\n\u001B[0;32m     86\u001B[0m             data, non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     87\u001B[0m         )\n\u001B[0;32m     88\u001B[0m     )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "labels = []\n",
    "\n",
    "pbar = tqdm(total=update_step*1000 + 1)\n",
    "for step in range(0, update_step*1000 + 1):\n",
    "    pbar_postfix = {}\n",
    "    if step % update_step == 0 and step > 0:\n",
    "        label_tensor = torch.tensor(labels)\n",
    "\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(\n",
    "            spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "        )\n",
    "        proportion_pred = proportion_weighting(\n",
    "            spikes=spike_record,\n",
    "            assignments=assignments,\n",
    "            proportions=proportions,\n",
    "            n_labels=n_classes,\n",
    "        )\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(\n",
    "            100\n",
    "            * torch.sum(label_tensor.long() == all_activity_pred).item()\n",
    "            / len(label_tensor)\n",
    "        )\n",
    "        accuracy[\"proportion\"].append(\n",
    "            100\n",
    "            * torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "            / len(label_tensor)\n",
    "        )\n",
    "        pbar_postfix['acc_all'] = accuracy[\"all\"][-1]\n",
    "        pbar_postfix['mean_all'] = np.mean(accuracy[\"all\"])\n",
    "        pbar_postfix['best_all'] = np.max(accuracy[\"all\"])\n",
    "\n",
    "        pbar_postfix['acc_prop'] = accuracy[\"proportion\"][-1]\n",
    "        pbar_postfix['mean_prop'] = np.mean(accuracy[\"proportion\"])\n",
    "        pbar_postfix['best_prop'] = np.max(accuracy[\"proportion\"])\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(\n",
    "            spikes=spike_record,\n",
    "            labels=label_tensor,\n",
    "            n_labels=n_classes,\n",
    "            rates=rates,\n",
    "        )\n",
    "\n",
    "        labels = []\n",
    "\n",
    "    inputs, label_tensor = merge_n_shuffle_tensors(labeled_inputs['focus'], labeled_inputs['unfocus'], labeled_inputs['drowsed'],\n",
    "                                                   label_tensor=origin_label_tensor)\n",
    "\n",
    "    inputs = {'X': torch.stack(list(inputs.values()), dim=2)}\n",
    "    labels.extend(label_tensor.tolist())\n",
    "\n",
    "    # Run the network on the input.\n",
    "    snn.run(inputs=inputs, time=sim_time)\n",
    "    s = spikes[output_layer_name].get(\"s\").permute((1, 0, 2))\n",
    "    spike_record[\n",
    "                (step * batch_size) % update_interval :\n",
    "                (step * batch_size % update_interval) + s.size(0)\n",
    "            ] = s\n",
    "\n",
    "    # Get voltage recording.\n",
    "    exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "    inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "    spikes_output = {\n",
    "        monitor_name: monitor.get('s')\n",
    "        for monitor_name, monitor in spikes.items()\n",
    "    }\n",
    "    for monitor_name, monitor in spikes.items():\n",
    "        pbar_postfix[f'{monitor_name}_s'] = monitor.get('s').sum()\n",
    "\n",
    "    # plot epoch\n",
    "    image = inputs[\"X\"][:, 0].sum(0).view(11, 11)\n",
    "    image = image/image.max()*255\n",
    "    inpt = inputs[\"X\"][:, 0].view(sim_time, 11*11).sum(0).view(11, 11)\n",
    "    lable = label_tensor[0]\n",
    "    input_exc_weights = snn.connections[(\"X\", \"Ae\")].w\n",
    "    square_weights = get_square_weights(\n",
    "        input_exc_weights.view(11*11, n_neurons), n_sqrt, 11\n",
    "    )\n",
    "    square_assignments = get_square_assignments(assignments, n_sqrt)\n",
    "    spikes_ = {\n",
    "        layer: spikes[layer].get(\"s\")[:, 0].contiguous() for layer in spikes\n",
    "    }\n",
    "    voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "    inpt_axes, inpt_ims = plot_input(\n",
    "        image, inpt, label=lable, axes=inpt_axes, ims=inpt_ims\n",
    "    )\n",
    "    spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)\n",
    "    weights_im = plot_weights(square_weights, im=weights_im)\n",
    "    assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
    "    perf_ax = plot_performance(\n",
    "        accuracy, x_scale=update_step * batch_size, ax=perf_ax\n",
    "    )\n",
    "    voltage_ims, voltage_axes = plot_voltages(\n",
    "        voltages, ims=voltage_ims, axes=voltage_axes, plot_type=\"line\"\n",
    "    )\n",
    "    plt.pause(1e-8)\n",
    "\n",
    "    snn.reset_state_variables()  # Reset state variables.\n",
    "    # pbar.set_postfix(pbar_postfix)\n",
    "    # pbar.update(1)\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
