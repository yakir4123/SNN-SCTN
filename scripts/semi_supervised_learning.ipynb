{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Tuple\n",
    "from snn.layers import SCTNLayer\n",
    "from snn.spiking_network import SpikingNetwork\n",
    "from snn.spiking_neuron import create_SCTN, BINARY\n",
    "from scripts.rwcp_resonators import create_neuron_for_labeling\n",
    "from helpers import neurons_labels, save_network_weights, load_network_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def create_neuron_for_labeling(synapses_weights,\n",
    "                               leakage_factor=1,\n",
    "                               leakage_period=100,\n",
    "                               theta=0):\n",
    "    neuron = create_SCTN()\n",
    "    neuron.synapses_weights = synapses_weights\n",
    "    neuron.leakage_factor = leakage_factor\n",
    "    neuron.leakage_period = leakage_period\n",
    "    neuron.theta = theta\n",
    "    neuron.threshold_pulse = 65 * len(synapses_weights)\n",
    "    neuron.activation_function = BINARY\n",
    "    return neuron\n",
    "\n",
    "def create_random_network(freqs, clk_freq, n_neurons):\n",
    "    # create network with n neurons as labels.\n",
    "    # The neurons are not learning yet.\n",
    "    network = SpikingNetwork(clk_freq)\n",
    "    labels_neurons = [\n",
    "        create_neuron_for_labeling(\n",
    "            np.random.random(len(freqs)) * 10,\n",
    "            leakage_factor=5,\n",
    "            leakage_period=200,\n",
    "            theta=-.4e-4\n",
    "        )\n",
    "        for _ in range(n_neurons)\n",
    "    ]\n",
    "    network.add_layer(SCTNLayer(labels_neurons), True)\n",
    "    for neuron in network.layers_neurons[-1].neurons:\n",
    "        network.log_out_spikes(neuron._id)\n",
    "    return network\n",
    "\n",
    "\n",
    "def train_test_files(label, train_ratio=.5, seed=42):\n",
    "    files_names = np.array(os.listdir(f\"../datasets/RWCP_spikes/{label}\"))\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    shuffle = np.random.permutation(len(files_names))\n",
    "    files_names = files_names[shuffle]\n",
    "    train = files_names[:int(len(files_names) * train_ratio)]\n",
    "    test = files_names[int(len(files_names) * train_ratio):]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def get_signals(test: bool, seed=42, train_ratio=.5, oversample=False) -> List[Tuple[str, str]]:\n",
    "    bottle_files, bottle_test_files = train_test_files('bottle1', seed=seed, train_ratio=train_ratio)\n",
    "    buzzer_files, buzzer_test_files = train_test_files('buzzer', seed=seed, train_ratio=train_ratio)\n",
    "    phone_files, phone_test_files = train_test_files('phone4', seed=seed, train_ratio=train_ratio)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if test:\n",
    "        bottle_files = bottle_test_files\n",
    "        buzzer_files = buzzer_test_files\n",
    "        phone_files = phone_test_files\n",
    "\n",
    "    if oversample:\n",
    "        labels_files = [bottle_files, buzzer_files, phone_files]\n",
    "        max_samples = max(map(len, labels_files))\n",
    "\n",
    "        def oversample(files):\n",
    "            extra_samples = max_samples - len(files)\n",
    "            choices = np.random.choice(len(files), extra_samples)\n",
    "            return np.concatenate([files, files[choices]])\n",
    "\n",
    "        bottle_files = oversample(bottle_files)\n",
    "        buzzer_files = oversample(buzzer_files)\n",
    "        phone_files = oversample(phone_files)\n",
    "\n",
    "    signals_files = [f'bottle1/{f}' for f in bottle_files] + \\\n",
    "                    [f'buzzer/{f}' for f in buzzer_files] + \\\n",
    "                    [f'phone4/{f}' for f in phone_files]\n",
    "    labels = ['bottle1'] * len(bottle_files) + \\\n",
    "             ['buzzer'] * len(buzzer_files) + \\\n",
    "             ['phone4'] * len(phone_files)\n",
    "\n",
    "    res = np.array(list(zip(signals_files, labels)))\n",
    "\n",
    "    shuffle = np.random.permutation(len(res))\n",
    "    return res[shuffle]\n",
    "\n",
    "\n",
    "def activate_stdp_to_same_label_neurons(network: SpikingNetwork,\n",
    "                                        label: str):\n",
    "    time_to_learn = 20e-3\n",
    "    tau = network.clk_freq * time_to_learn / 2\n",
    "\n",
    "    for neuron in network.layers_neurons[-1].neurons:\n",
    "        if neuron.label == label:\n",
    "            neuron.set_stdp(1e-4, -8e-5, tau, clk_freq, 25, -20)\n",
    "\n",
    "\n",
    "def activate_stdp_to_different_label_neurons(network: SpikingNetwork,\n",
    "                                             label: str):\n",
    "    time_to_learn = 20e-3\n",
    "    tau = network.clk_freq * time_to_learn / 2\n",
    "\n",
    "    for neuron in network.layers_neurons[-1].neurons:\n",
    "        if neuron.label != label and neuron.label is not None:\n",
    "            neuron.set_stdp(-1e-5, 0, tau, clk_freq, 25, -20)\n",
    "\n",
    "\n",
    "def load_spikes_data(file_name, freqs, length=None):\n",
    "    spikes = pd.DataFrame \\\n",
    "        .from_dict(dict(\n",
    "            np.load(f'..\\datasets\\RWCP_spikes\\\\{file_name}')\n",
    "        ))\n",
    "    columns = [f'f{f}' for f in freqs]\n",
    "    res = spikes[columns].to_numpy()\n",
    "    if length is None:\n",
    "        return res\n",
    "    last_start_point = len(res) - length\n",
    "    if last_start_point <= 0:\n",
    "        return res\n",
    "\n",
    "    start_point = np.random.randint(last_start_point)\n",
    "    return res[start_point:start_point+length]\n",
    "\n",
    "\n",
    "def get_unlabeled_neurons(network: SpikingNetwork) -> np.ndarray:\n",
    "    unlabeled_neurons = [neuron.label is None\n",
    "                         for neuron in network.layers_neurons[-1].neurons]\n",
    "    return np.array(unlabeled_neurons, dtype=np.int8)\n",
    "\n",
    "\n",
    "def tag_neuron_a_label(network, post_spikes, label):\n",
    "    arg_most_active_neuron = np.argmax(post_spikes)\n",
    "    most_active_neuron = network.layers_neurons[-1].neurons[arg_most_active_neuron]\n",
    "    if most_active_neuron.label is None:\n",
    "        most_active_neuron.label = label\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def learning_process(network: SpikingNetwork,\n",
    "                     train_signals: List[Tuple[str, str]],\n",
    "                     epochs: int,\n",
    "                     l1_stop: float = .1):\n",
    "    neurons_encoder = {\n",
    "        None: '-',\n",
    "        'bottle1': 'ðŸ¶',\n",
    "        'buzzer': 'ðŸš¨',\n",
    "        'phone4': 'ðŸ“±'\n",
    "    }\n",
    "    total_runs = epochs * len(train_signals)\n",
    "\n",
    "    labels_neurons = network.layers_neurons[-1].neurons\n",
    "    weight_generations_buffer = np.zeros((epochs * len(train_signals) + 1,\n",
    "                                          len(labels_neurons),\n",
    "                                          len(labels_neurons[0].synapses_weights)))\n",
    "\n",
    "    for n, neuron in enumerate(labels_neurons):\n",
    "        weight_generations_buffer[0, n, :] = neuron.synapses_weights\n",
    "\n",
    "    count_labels = {\n",
    "        'bottle1': len(labels_neurons) // 3,\n",
    "        'buzzer': len(labels_neurons) // 3,\n",
    "        'phone4': len(labels_neurons) // 3\n",
    "    }\n",
    "    with tqdm(total=total_runs) as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            permutation_audio_file_indices = np.random.permutation(len(train_signals))\n",
    "            for signal_index in range(len(train_signals)):\n",
    "                i = epoch * len(train_signals) + signal_index\n",
    "                signal, label = train_signals[permutation_audio_file_indices[signal_index]]\n",
    "                activate_stdp_to_same_label_neurons(network, label)\n",
    "                activate_stdp_to_different_label_neurons(network, label)\n",
    "\n",
    "                spikes = load_spikes_data(signal, freqs, length=network.clk_freq)\n",
    "\n",
    "                post_spikes = network.input_full_data_spikes(\n",
    "                    spikes,\n",
    "                    False       # don't stop_on_first_spike\n",
    "                )\n",
    "                # post_spikes *= get_unlabeled_neurons(network)\n",
    "                if count_labels[label] > 0 and tag_neuron_a_label(network, post_spikes, label):\n",
    "                    # if new neuron got a label, count it.\n",
    "                    count_labels[label] -= 1\n",
    "\n",
    "                for n, neuron in enumerate(labels_neurons):\n",
    "                    weight_generations_buffer[i+1, n, :] = neuron.synapses_weights\n",
    "\n",
    "                # prepare for new input\n",
    "                network.reset_learning()\n",
    "                network.reset_input()\n",
    "\n",
    "                l1 = np.sum(\n",
    "                    np.abs(\n",
    "                        weight_generations_buffer[i + 1, :, :] -\n",
    "                        weight_generations_buffer[epoch * len(train_signals), :, :]\n",
    "                    )\n",
    "                )\n",
    "                predicted, prediction_spikes = predict_label(\n",
    "                    count_labels.keys(),\n",
    "                    network.layers_neurons[-1].neurons,\n",
    "                    post_spikes\n",
    "                )\n",
    "                pbar.set_description(\n",
    "                    f\"l1 {l1:.2f} | {label} {'V' if label == predicted else 'X'} {prediction_spikes}  | {neurons_labels(network.layers_neurons[-1].neurons, encoder=neurons_encoder, spikes=post_spikes)}\")\n",
    "                # pbar.refresh()\n",
    "                pbar.update()\n",
    "\n",
    "            np.savez_compressed(f'neurons_weights/synapses_weights_generations.npz',\n",
    "                                synapses_weights=weight_generations_buffer)\n",
    "            save_network_weights(network, path=f'neurons_weights/semi_supervised_learning_e{epoch}.pickle')\n",
    "            l1 = np.sum(\n",
    "                np.abs(\n",
    "                    weight_generations_buffer[(epoch + 1) * len(train_signals), :] -\n",
    "                    weight_generations_buffer[epoch * len(train_signals), :]\n",
    "                )\n",
    "            )\n",
    "            if epoch > 0 and l1 < l1_stop:\n",
    "                return\n",
    "\n",
    "def predict_label(labels, neurons, post_spikes):\n",
    "    labels_counter = {label: 0 for label in labels}\n",
    "    for i, neuron in enumerate(neurons):\n",
    "        if neuron.label is not None:\n",
    "            labels_counter[neuron.label] += post_spikes[i]\n",
    "    return max(labels_counter.items(), key=operator.itemgetter(1))[0], \\\n",
    "        dict(sorted(labels_counter.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "\n",
    "def test_process(network, test_signal_files):\n",
    "    labels = [f'{n.label}_{n._id}' for n in network.layers_neurons[-1].neurons]\n",
    "    predict_results = []\n",
    "    for signal_file, label in tqdm(test_signal_files):\n",
    "        spikes = load_spikes_data(signal_file, freqs)\n",
    "        post_spikes = network.input_full_data_spikes(spikes)\n",
    "        res = dict(zip(labels, post_spikes))\n",
    "        res['label'] = label\n",
    "        predict_results.append(res)\n",
    "        network.reset_input()\n",
    "\n",
    "    df = pd.DataFrame.from_records(predict_results)\n",
    "    df.to_csv('output_spikes/semi_supervised_test.csv', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def semi_supervised_learning(freqs, clk_freq, n_neurons, epochs=1, train_ratio=.5):\n",
    "    network = create_random_network(freqs, clk_freq, n_neurons)\n",
    "    train_signals_files = get_signals(test=False, train_ratio=train_ratio, oversample=True)\n",
    "    learning_process(network, train_signals_files, epochs=epochs, l1_stop=.1)\n",
    "    save_network_weights(network,\n",
    "                         path='neurons_weights/semi_supervised_learning.pickle')\n",
    "    return network\n",
    "\n",
    "\n",
    "def test_network(network=None,\n",
    "                 freqs=None,\n",
    "                 clk_freq=None,\n",
    "                 n_neurons=None,\n",
    "                 train_ratio=.5):\n",
    "    if network is None:\n",
    "        network = create_random_network(freqs, clk_freq, n_neurons)\n",
    "        load_network_weights(network, path='neurons_weights/semi_supervised_learning.pickle')\n",
    "    test_signals_files = get_signals(test=True, train_ratio=train_ratio, oversample=False)\n",
    "    return test_process(network, test_signals_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82523a231d43498db8e48047d0d73c7d"
      },
      "application/json": {
       "n": 0,
       "total": 1500,
       "elapsed": 0.0030753612518310547,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m clk_freq \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1.536\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m6\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      3\u001B[0m freqs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;241m236\u001B[39m, \u001B[38;5;241m751\u001B[39m, \u001B[38;5;241m887\u001B[39m, \u001B[38;5;241m1046\u001B[39m, \u001B[38;5;241m1235\u001B[39m, \u001B[38;5;241m2029\u001B[39m, \u001B[38;5;241m2825\u001B[39m, \u001B[38;5;241m3934\u001B[39m, \u001B[38;5;241m5478\u001B[39m\n\u001B[0;32m      5\u001B[0m ]\n\u001B[1;32m----> 7\u001B[0m network \u001B[38;5;241m=\u001B[39m \u001B[43msemi_supervised_learning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfreqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mclk_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mn_neurons\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mtrain_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m.5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[18], line 243\u001B[0m, in \u001B[0;36msemi_supervised_learning\u001B[1;34m(freqs, clk_freq, n_neurons, epochs, train_ratio)\u001B[0m\n\u001B[0;32m    241\u001B[0m network \u001B[38;5;241m=\u001B[39m create_random_network(freqs, clk_freq, n_neurons)\n\u001B[0;32m    242\u001B[0m train_signals_files \u001B[38;5;241m=\u001B[39m get_signals(test\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, train_ratio\u001B[38;5;241m=\u001B[39mtrain_ratio, oversample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 243\u001B[0m \u001B[43mlearning_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_signals_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml1_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    244\u001B[0m save_network_weights(network,\n\u001B[0;32m    245\u001B[0m                      path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneurons_weights/semi_supervised_learning.pickle\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m network\n",
      "Cell \u001B[1;32mIn[18], line 170\u001B[0m, in \u001B[0;36mlearning_process\u001B[1;34m(network, train_signals, epochs, l1_stop)\u001B[0m\n\u001B[0;32m    166\u001B[0m activate_stdp_to_different_label_neurons(network, label)\n\u001B[0;32m    168\u001B[0m spikes \u001B[38;5;241m=\u001B[39m load_spikes_data(signal, freqs, length\u001B[38;5;241m=\u001B[39mnetwork\u001B[38;5;241m.\u001B[39mclk_freq)\n\u001B[1;32m--> 170\u001B[0m post_spikes \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_full_data_spikes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    171\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspikes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m       \u001B[49m\u001B[38;5;66;43;03m# don't stop_on_first_spike\u001B[39;49;00m\n\u001B[0;32m    173\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;66;03m# post_spikes *= get_unlabeled_neurons(network)\u001B[39;00m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m count_labels[label] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m tag_neuron_a_label(network, post_spikes, label):\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;66;03m# if new neuron got a label, count it.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\numba\\experimental\\jitclass\\boxing.py:59\u001B[0m, in \u001B[0;36m_generate_method.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m method(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Projects\\Thesis\\code\\SNN-SCTN\\venv\\lib\\site-packages\\numba\\core\\serialize.py:43\u001B[0m, in \u001B[0;36m_numba_unpickle\u001B[1;34m(address, bytedata, hashed)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numba_unpickle\u001B[39m(address, bytedata, hashed):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;124;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \n\u001B[0;32m     32\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;124;03m        unpickled object\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m     key \u001B[38;5;241m=\u001B[39m (address, hashed)\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     45\u001B[0m         obj \u001B[38;5;241m=\u001B[39m _unpickled_memo[key]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "clk_freq = int(1.536 * (10 ** 6) * 2)\n",
    "\n",
    "freqs = [\n",
    "    236, 751, 887, 1046, 1235, 2029, 2825, 3934, 5478\n",
    "]\n",
    "\n",
    "network = semi_supervised_learning(freqs,\n",
    "                                   clk_freq,\n",
    "                                   n_neurons=3 * 10,\n",
    "                                   epochs=10,\n",
    "                                   train_ratio=.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = test_network(network,\n",
    "             train_ratio=.5)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      label  phone4  buzzer  bottle1 predicted_label  success\n0    buzzer  1416.0    84.0     27.0          phone4    False\n1    phone4  4709.0    72.0     30.0          phone4     True\n2   bottle1   339.0    15.0      9.0          phone4    False\n3    phone4  6072.0    55.0     20.0          phone4     True\n4    buzzer  2985.0    46.0     27.0          phone4    False\n5    buzzer  2962.0    50.0     21.0          phone4    False\n6    buzzer  2252.0    64.0     24.0          phone4    False\n7   bottle1   347.0   114.0     34.0          phone4    False\n8    phone4  5446.0    12.0     14.0          phone4     True\n9   bottle1   354.0    10.0      4.0          phone4    False\n10  bottle1   243.0    11.0      7.0          phone4    False\n11   buzzer  2670.0    29.0     24.0          phone4    False\n12   buzzer  2259.0    30.0     16.0          phone4    False\n13  bottle1   326.0   102.0     30.0          phone4    False\n14  bottle1   297.0     9.0      5.0          phone4    False\n15   phone4  3010.0    12.0      4.0          phone4     True\n16   phone4  2354.0     8.0      3.0          phone4     True\n17   phone4  2578.0     7.0      3.0          phone4     True\n18   phone4  2209.0    21.0     12.0          phone4     True\n19   phone4  1507.0     8.0      3.0          phone4     True\n20   phone4  2433.0     5.0      2.0          phone4     True\n21   buzzer   829.0    28.0     15.0          phone4    False\n22   buzzer   836.0    26.0      2.0          phone4    False\n23   buzzer   482.0    27.0     20.0          phone4    False\n24   phone4  3082.0    21.0     20.0          phone4     True\n25   buzzer   531.0     6.0      4.0          phone4    False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>phone4</th>\n      <th>buzzer</th>\n      <th>bottle1</th>\n      <th>predicted_label</th>\n      <th>success</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>buzzer</td>\n      <td>1416.0</td>\n      <td>84.0</td>\n      <td>27.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>phone4</td>\n      <td>4709.0</td>\n      <td>72.0</td>\n      <td>30.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bottle1</td>\n      <td>339.0</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>phone4</td>\n      <td>6072.0</td>\n      <td>55.0</td>\n      <td>20.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>buzzer</td>\n      <td>2985.0</td>\n      <td>46.0</td>\n      <td>27.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>buzzer</td>\n      <td>2962.0</td>\n      <td>50.0</td>\n      <td>21.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>buzzer</td>\n      <td>2252.0</td>\n      <td>64.0</td>\n      <td>24.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bottle1</td>\n      <td>347.0</td>\n      <td>114.0</td>\n      <td>34.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>phone4</td>\n      <td>5446.0</td>\n      <td>12.0</td>\n      <td>14.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>bottle1</td>\n      <td>354.0</td>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>bottle1</td>\n      <td>243.0</td>\n      <td>11.0</td>\n      <td>7.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>buzzer</td>\n      <td>2670.0</td>\n      <td>29.0</td>\n      <td>24.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>buzzer</td>\n      <td>2259.0</td>\n      <td>30.0</td>\n      <td>16.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>bottle1</td>\n      <td>326.0</td>\n      <td>102.0</td>\n      <td>30.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>bottle1</td>\n      <td>297.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>phone4</td>\n      <td>3010.0</td>\n      <td>12.0</td>\n      <td>4.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>phone4</td>\n      <td>2354.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>phone4</td>\n      <td>2578.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>phone4</td>\n      <td>2209.0</td>\n      <td>21.0</td>\n      <td>12.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>phone4</td>\n      <td>1507.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>phone4</td>\n      <td>2433.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>buzzer</td>\n      <td>829.0</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>buzzer</td>\n      <td>836.0</td>\n      <td>26.0</td>\n      <td>2.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>buzzer</td>\n      <td>482.0</td>\n      <td>27.0</td>\n      <td>20.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>phone4</td>\n      <td>3082.0</td>\n      <td>21.0</td>\n      <td>20.0</td>\n      <td>phone4</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>buzzer</td>\n      <td>531.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>phone4</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['phone4', 'buzzer', 'bottle1']\n",
    "columns_labels = {\n",
    "    label: [c for c in res.columns if c.startswith(label)]\n",
    "    for label in labels\n",
    "  }\n",
    "\n",
    "\n",
    "sum_spikes_df = pd.DataFrame()\n",
    "sum_spikes_df['label'] = res['label']\n",
    "for label, columns in columns_labels.items():\n",
    "  sum_spikes_df[f'{label}'] = res[columns].sum(axis=1)\n",
    "sum_spikes_df['predicted_label'] = sum_spikes_df[labels].idxmax(axis=1)\n",
    "sum_spikes_df['success'] = sum_spikes_df['predicted_label'] == sum_spikes_df['label']\n",
    "sum_spikes_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}